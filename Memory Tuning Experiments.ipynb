{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed90c8e-6a6b-4ecb-8381-583fd709116e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b43faf7-f71c-4d2b-a465-8548e7072cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import lamini\n",
    "import pandas as pd\n",
    "\n",
    "from contract_poc.utils import read_pdf, build_prompts_from_dataframe, load_format_pages\n",
    "from contract_poc.qa_pipeline import QuestionAnswerPipeline, load_qa_prompts, save_answers\n",
    "from contract_poc.answer_pipeline import AnswerPipeline\n",
    "from contract_poc.rag_pipeline import RAGPipeline\n",
    "from contract_poc.gen_pipeline import GenPipeline, simple_prompt_generator, save_answers_to_csv\n",
    "from contract_poc.summary_pipeline import SummaryPipeline, save_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b84e0-debe-40c3-8148-a25594020191",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e3e604-94ff-40d3-a56b-0b0b4e8f4321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uber number of pages: 307\n"
     ]
    }
   ],
   "source": [
    "uber_text = read_pdf(\"data/uber_2021.pdf\")\n",
    "print(f\"Uber number of pages: {len(uber_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152c9b5c-1d91-4b2c-9e38-cca23e670459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyft number of pages: 238\n"
     ]
    }
   ],
   "source": [
    "lyft_text = read_pdf(\"data/lyft_2021.pdf\")\n",
    "print(f\"Lyft number of pages: {len(lyft_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc45431-d00c-4bb9-9242-18b417d385fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = []\n",
    "with jsonlines.Reader(open(os.path.join(\"eval_sets\",\"gold-test-set.jsonlines\"), \"rb\")) as reader:\n",
    "    for line in reader:\n",
    "        eval_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80e9e268-15a8-46ed-8552-095edb3b0a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What countries does Uber operate in?',\n",
       "  'answer': 'Our technology is available in approximately 72 countries around the world, principally in the United States (“U.S.”) and Canada, Latin America, Europe, the Middle East, Africa, and Asia (excluding China and Southeast Asia).'},\n",
       " {'question': 'What countries does Lyft operate in?',\n",
       "  'answer': 'United states and select cities in Canada'},\n",
       " {'question': 'Do Uber and Lyft operate in Mexico?',\n",
       "  'answer': 'Uber operates in Mexico including ride sharing and delivery services. Lyft only operates in the United States and select cities in Canada.'},\n",
       " {'question': \"Think step by step. First, consider the largest spanish speaking north american country that lyft operates in. Second describe any recent regulation that impacts Lyft's business in that market.\",\n",
       "  'answer': 'Lyft only operates in canada and the united states.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f1ddf7-14f1-4386-9397-5ce62c1eb839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What countries does Uber operate in?</td>\n",
       "      <td>Our technology is available in approximately 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What countries does Lyft operate in?</td>\n",
       "      <td>United states and select cities in Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do Uber and Lyft operate in Mexico?</td>\n",
       "      <td>Uber operates in Mexico including ride sharing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Think step by step. First, consider the larges...</td>\n",
       "      <td>Lyft only operates in canada and the united st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Think step by step. First, consider the larges...</td>\n",
       "      <td>Uber operates in mexico. Since April 2019, Mex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0               What countries does Uber operate in?   \n",
       "1               What countries does Lyft operate in?   \n",
       "2                Do Uber and Lyft operate in Mexico?   \n",
       "3  Think step by step. First, consider the larges...   \n",
       "4  Think step by step. First, consider the larges...   \n",
       "\n",
       "                                              answer  \n",
       "0  Our technology is available in approximately 7...  \n",
       "1          United states and select cities in Canada  \n",
       "2  Uber operates in Mexico including ride sharing...  \n",
       "3  Lyft only operates in canada and the united st...  \n",
       "4  Uber operates in mexico. Since April 2019, Mex...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(eval_data)\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e5c52-ab1e-45ba-a968-61cb6c7956dd",
   "metadata": {},
   "source": [
    "# Eval Criteria\n",
    "\n",
    "* Accurate information - Facts can be sourced to a ground truth\n",
    "* Correct context - Extrapolation of the model is still in the context of the question\n",
    "* Just enough information - No run on thoughts, just answer the question\n",
    "\n",
    "Accurate\n",
    "* Response is factually accurate, doesn't extend the answer beyond the scope of the question\n",
    "\n",
    "Mixed\n",
    "* Response contains the correct information, but either the context extended beyond the question or additional facts are added that have nothing to do with the question\n",
    "\n",
    "Incorrect\n",
    "* Any fact is not accurate, response may not include corret context\n",
    "\n",
    "Successful Failure\n",
    "* Model recognizes that it does not know the answer, interesting to see how well the model catches itself. This is helpful for UX purposes, and it would be good to have incorrect responses be this category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13bed46-86fd-4ebb-a688-18442d8aa545",
   "metadata": {},
   "source": [
    "# Base Llama Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adf6b8dc-8de0-4255-b91c-2b5df5eff4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979122866b1d414eae46d163c535348f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "llama_3_1_responses = await save_answers_to_csv(answers, path=\"responses/base_llama_3_1_response.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6a06c-110d-4566-88c5-58a756e2c414",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/1zctM75Pd3dprofVs2Caky3kAv1LnyU1Z2hnxhbFeyPI/edit?usp=sharing\n",
    "\n",
    "Correct: 3 (0.15)\n",
    "\n",
    "Mixed: 7 (0.35)\n",
    "\n",
    "Incorrect: 9 (0.45)\n",
    "\n",
    "Successfull Failure: 1 (0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2b9d45b-52e1-4014-85ce-5a921ff2b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163f779ad73447de8009c75352b7654d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "llama_3_2_responses = await save_answers_to_csv(answers, path=\"responses/base_llama_3_2_response.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d5d9a-a17c-4297-9829-3e0186920c42",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/1WrILF9GV6RS09LTQ2fHUHtH6SJs5v2DN61Ia55fIxME/edit?usp=sharing\n",
    "\n",
    "Correct: 2 (0.1)\n",
    "\n",
    "Mixed: 4 (0.2)\n",
    "\n",
    "Incorrect: 13 (0.65)\n",
    "\n",
    "Successfull Failure: 1 (0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd4ca0f0-fad5-49fa-aadd-c215aac54b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2d289eccbb4f6c921a6a92031a6dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: API error 524\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 150, in make_async_web_request\n",
      "    await handle_error(resp)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 252, in handle_error\n",
      "    raise APIError(f\"API error {description}\")\n",
      "lamini.error.error.APIError: API error 524\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n",
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: API error 524\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 150, in make_async_web_request\n",
      "    await handle_error(resp)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 252, in handle_error\n",
      "    raise APIError(f\"API error {description}\")\n",
      "lamini.error.error.APIError: API error 524\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n",
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: API error 524\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 150, in make_async_web_request\n",
      "    await handle_error(resp)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 252, in handle_error\n",
      "    raise APIError(f\"API error {description}\")\n",
      "lamini.error.error.APIError: API error 524\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n",
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: API error 524\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 150, in make_async_web_request\n",
      "    await handle_error(resp)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 252, in handle_error\n",
      "    raise APIError(f\"API error {description}\")\n",
      "lamini.error.error.APIError: API error 524\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n"
     ]
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"google/gemma-2-9b-it\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "gemma_2_responses = await save_answers_to_csv(answers, path=\"responses/base_gemma_2_response.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1aee21-5441-4b81-8c64-936c7e15f703",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/1W3TOvj-2s3zvr8nIInPSf6lTzyjwjmexzEYtCKJBHb8/edit?usp=sharing\n",
    "\n",
    "Correct: 8 (0.4)\n",
    "\n",
    "Mixed: 6 (0.3)\n",
    "\n",
    "Incorrect: 3 (0.15)\n",
    "\n",
    "Successfull Failure: 3 (0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c70954-ee89-46d4-b973-50675742e372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf3ead31e2342d184622d0de957d215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "mistral_responses = await save_answers_to_csv(answers, path=\"responses/base_mistral_7B_response.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff845ed3-c720-4e96-aa8d-878a012ce821",
   "metadata": {},
   "source": [
    "# RAG Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c53623-2bae-465d-8d0c-66bcd65febe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lamini.index.lamini_index import LaminiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27dd8e5f-03af-40b1-8d98-9944beb82079",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_index = LaminiIndex.load_index(\"model_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1124b9a1-0bd6-4b5e-94a5-7e8e385fc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = llm_index.get_embeddings(\"Ask three separate questions around a fact, table, or number within this text:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471166d-394c-40c8-9ed5-cf34ed85c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = llm_index.index.search(embed, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de463d-81da-4b38-9c55-ab61c6bf41d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[llm_index.splits[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5d456a-f1bb-45ff-8923-9d34bcb07f1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78074be04f7a4724b54a206e6fd14ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_rag = RAGPipeline(rag_model_path=\"model_index\", model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "answers = llm_rag.call(simple_prompt_generator(eval_df))\n",
    "rag_3_1_responses = await save_answers_to_csv(answers, path=\"responses/rag_llama_3_1_response.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa164b00-b530-434f-8489-49b167aa7c24",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/17cl6vp8cEaAo3MmATy3L9zJyW37jHf4AQSfXaKKKr5s/edit?usp=sharing\n",
    "\n",
    "Correct: 3 (0.15)\n",
    "\n",
    "Mixed: 2 (0.1)\n",
    "\n",
    "Incorrect: 1 (0.05)\n",
    "\n",
    "Successfull Failure: 14 (0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db824807-08d8-4581-9932-a41e2fdba93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6d1f3a3a5d48d2a37118b4ca0a098d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_rag = RAGPipeline(rag_model_path=\"model_index\", model_name = \"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "answers = llm_rag.call(simple_prompt_generator(eval_df))\n",
    "rag_3_2_responses = await save_answers_to_csv(answers, path=\"responses/rag_llama_3_2_response.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12bf8e6-bcfa-48d4-b702-a123e72d5495",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/1y9341YAzY0NDFIuF54PWpb-j3IW1gHMGe1afGwo7tjU/edit?usp=sharing\n",
    "\n",
    "Correct: 4 (0.2)\n",
    "\n",
    "Mixed: 1 (0.05)\n",
    "\n",
    "Incorrect: 1 (0.05)\n",
    "\n",
    "Successfull Failure: 14 (0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0132a74-1c25-4fbd-8a69-360c22b5767c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4f2b2e1e2a418582f96ba452ac1143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_rag = RAGPipeline(rag_model_path=\"model_index\", model_name = \"google/gemma-2-9b-it\", rag_query_size=1)\n",
    "answers = llm_rag.call(simple_prompt_generator(eval_df))\n",
    "rag_gemma_2_responses = await save_answers_to_csv(answers, path=\"responses/rag_gemma_2_response.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5de4c286-8d89-410d-93e8-c267be8c4a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000cae1c2dfc4f9d8e0181dd64669585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_rag = RAGPipeline(rag_model_path=\"model_index\", model_name = \"mistralai/Mistral-7B-Instruct-v0.3\", rag_query_size=1)\n",
    "answers = llm_rag.call(simple_prompt_generator(eval_df))\n",
    "rag_mistral_responses = await save_answers_to_csv(answers, path=\"responses/rag_mistral_7B_response.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed0cbd0-f0e8-4f1f-84d7-0664201d0e53",
   "metadata": {},
   "source": [
    "# Tuning Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c41f0b2-83dd-4cab-87b6-0317ac282115",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69f03d76-9dd4-4322-986d-e81012dc73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_data = []\n",
    "for idx, row in eval_df.iterrows():\n",
    "    new_item = {\n",
    "        \"input\": row[\"question\"],\n",
    "        \"output\": row[\"answer\"]\n",
    "    }\n",
    "    tune_data.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edaad277-425d-4d66-b102-4ea7a6c90baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: 7be6259d864fd673649461e0578126a8bf158a6ae29516d92503b35777b72577 . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='7be6259d864fd673649461e0578126a8bf158a6ae29516d92503b35777b72577')\n",
      "Tuning job submitted! Check status of job 13812 here: https://api.lamini.ai/train/13812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13812,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': '7be6259d864fd673649461e0578126a8bf158a6ae29516d92503b35777b72577'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_llm = lamini.Lamini(model_name=\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "base_llm.tune(tune_data, finetune_args={\"max_steps\": 500, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49ae4f4e-1915-46f4-8bbb-a0a36bcf1d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4123d367b14069911c08ef615b34a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"2d8f64af8f9c3ef80832ca2aadfdb7d0043fabfd819961293e169f768ba31225\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13812.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20bee67b-75c8-4a22-9b63-c2ddcee82a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: 95e9cd9f82df5a7fd3e2fc979097a3e44dba0d941974ee3e44bcda58c3334cde . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='95e9cd9f82df5a7fd3e2fc979097a3e44dba0d941974ee3e44bcda58c3334cde')\n",
      "Tuning job submitted! Check status of job 13813 here: https://api.lamini.ai/train/13813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13813,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': '95e9cd9f82df5a7fd3e2fc979097a3e44dba0d941974ee3e44bcda58c3334cde'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_llm = lamini.Lamini(model_name=\"google/gemma-2-9b-it\")\n",
    "base_llm.tune(tune_data, finetune_args={\"max_steps\": 500, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49d3c631-7ed8-4518-94d9-a3cd23d9c03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c06d6d463ba4404a1f0b0246d443187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"e5efa53e755a7d0d6aba230292dd862c8be2634408f8b17ded5db404228ca448\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13813.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6615d64-8fb3-49f4-9dcc-8d97faff2e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: e42a7c62960acf57811e214d52bfe38934d7d598d081ccb1d42544d37d671672 . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='e42a7c62960acf57811e214d52bfe38934d7d598d081ccb1d42544d37d671672')\n",
      "Tuning job submitted! Check status of job 13814 here: https://api.lamini.ai/train/13814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13814,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': 'e42a7c62960acf57811e214d52bfe38934d7d598d081ccb1d42544d37d671672'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_llm = lamini.Lamini(model_name=\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "base_llm.tune(tune_data, finetune_args={\"max_steps\": 500, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53a2c8bb-06d7-4ead-8ecb-07f258a17468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0906f414166496b9715fce6d96cb799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"5997c763d14769bf00a89818f8dcaf51d4d67b30b5a9e5c9ae24bfd977605ea9\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13814.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4588be-94e3-4511-9ee2-aaa048360576",
   "metadata": {},
   "source": [
    "## Automatic QA Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31f38c-9977-4897-bda8-3bdabc7af3e9",
   "metadata": {},
   "source": [
    "### V1\n",
    "\n",
    "Job ID: 13265\n",
    "\n",
    "Model ID: d9341ae5cfc60d5ed9e173954387404b6419ee201aa2baacb79fe4a6cef532a1\n",
    "\n",
    "This is from an initial overfit run in the Contracts Data Discovery notebook, this was to overfit to a set of automatically extracted QA pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47a919f1-7167-4eff-84a3-a2ba7f39769c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19d4308b08747c08e295c8c194e9d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"d9341ae5cfc60d5ed9e173954387404b6419ee201aa2baacb79fe4a6cef532a1\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13265.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f04bc-4826-4a09-9793-77d29ce3a3be",
   "metadata": {},
   "source": [
    "### Eval\n",
    "\n",
    "Correct: 5 (0.25)\n",
    "\n",
    "Mixed: 7 (0.35)\n",
    "\n",
    "Incorrect: 6 (0.3)\n",
    "\n",
    "Successfull Failure: 2 (0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e0bfc-1fa8-48fd-bcaf-a5213bff1f62",
   "metadata": {},
   "source": [
    "### V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13743aec-6efe-41ab-b546-17ed2ea6159f",
   "metadata": {},
   "source": [
    "#### Generate QA Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c254c403-0d9c-4db5-8920-a45354de8a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pipeline = QuestionAnswerPipeline(\n",
    "    question_system_prompt = \"Ask three separate questions around a fact, table, or number within this text: \\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b16ad-8a9c-41f8-bcdf-92598cbba523",
   "metadata": {},
   "source": [
    "##### Uber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05ce0355-c5a5-479d-ab58-7b4d57d484a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92637cde7bc0450a9655e83d814a0831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers = qa_pipeline.call(load_qa_prompts([uber_text[page] for page in uber_text]))\n",
    "await save_answers(answers, path=\"uber_generated_qa.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcbac24-80cc-4c21-9dde-4de8369a0b06",
   "metadata": {},
   "source": [
    "##### Lyft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ef8cc0-02b2-4c37-8daf-1965d7fe3c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfc0d524cbc49e7af4bdf81d9d3892d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers = qa_pipeline.call(load_qa_prompts([lyft_text[page] for page in lyft_text]))\n",
    "await save_answers(answers, path=\"lyft_generated_qa.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff006067-d26f-4a94-a4cc-92822f52cda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_data = []\n",
    "with jsonlines.Reader(open(\"uber_generated_qa.jsonl\", \"rb\")) as reader:\n",
    "    for line in reader:\n",
    "        line[\"input\"] = line[\"question\"]\n",
    "        line[\"output\"] = line[\"answer\"]\n",
    "        tune_data.append(line)\n",
    "with jsonlines.Reader(open(\"lyft_generated_qa.jsonl\", \"rb\")) as reader:\n",
    "    for line in reader:\n",
    "        line[\"input\"] = line[\"question\"]\n",
    "        line[\"output\"] = line[\"answer\"]\n",
    "        tune_data.append(line)\n",
    "tune_df = pd.DataFrame(tune_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ded3c02f-c28c-487c-8fe7-f11f2ac934f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>What is the name of the company that is filing...</td>\n",
       "      <td>UBER TECHNOLOGIES, INC</td>\n",
       "      <td>What is the name of the company that is filing...</td>\n",
       "      <td>UBER TECHNOLOGIES, INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>What is the state of incorporation of the company</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>What is the state of incorporation of the company</td>\n",
       "      <td>Delaware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>What is the name of the exchange on which the ...</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "      <td>What is the name of the exchange on which the ...</td>\n",
       "      <td>New York Stock Exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>What is the number of shares of the registrant...</td>\n",
       "      <td>1,954,464,088</td>\n",
       "      <td>What is the number of shares of the registrant...</td>\n",
       "      <td>1,954,464,088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_...</td>\n",
       "      <td>What is the aggregate market value of the voti...</td>\n",
       "      <td>approximately $90.5 billion</td>\n",
       "      <td>What is the aggregate market value of the voti...</td>\n",
       "      <td>approximately $90.5 billion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "1  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "2  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "3  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "4  <|begin_of_text|><|start_header_id|>user<|end_...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What is the name of the company that is filing...   \n",
       "1  What is the state of incorporation of the company   \n",
       "2  What is the name of the exchange on which the ...   \n",
       "3  What is the number of shares of the registrant...   \n",
       "4  What is the aggregate market value of the voti...   \n",
       "\n",
       "                        answer  \\\n",
       "0       UBER TECHNOLOGIES, INC   \n",
       "1                     Delaware   \n",
       "2      New York Stock Exchange   \n",
       "3                1,954,464,088   \n",
       "4  approximately $90.5 billion   \n",
       "\n",
       "                                               input  \\\n",
       "0  What is the name of the company that is filing...   \n",
       "1  What is the state of incorporation of the company   \n",
       "2  What is the name of the exchange on which the ...   \n",
       "3  What is the number of shares of the registrant...   \n",
       "4  What is the aggregate market value of the voti...   \n",
       "\n",
       "                        output  \n",
       "0       UBER TECHNOLOGIES, INC  \n",
       "1                     Delaware  \n",
       "2      New York Stock Exchange  \n",
       "3                1,954,464,088  \n",
       "4  approximately $90.5 billion  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0a07955-75be-4ab8-8a95-2b58e67a85c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: f00cbe4f6103fc99b731b351f7d963ac779909ca5f13cc7063c113e55d665f52 . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='f00cbe4f6103fc99b731b351f7d963ac779909ca5f13cc7063c113e55d665f52')\n",
      "Tuning job submitted! Check status of job 13695 here: https://api.lamini.ai/train/13695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13695,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': 'f00cbe4f6103fc99b731b351f7d963ac779909ca5f13cc7063c113e55d665f52'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_llm = lamini.Lamini(model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "base_llm.tune(tune_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee334216-14c8-4180-a659-db9d7700011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3714f8d7f64370b91b1ba02e486081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"6bbfc54db98cb502a629aa5c3ed0aba4372fd2ad795ea694042ba6105ba892b4\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13695.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003f92e-bab7-4376-87b9-523b280968e5",
   "metadata": {},
   "source": [
    "##### Eval\n",
    "\n",
    "Job ID: 13695\n",
    "\n",
    "Model ID: 6bbfc54db98cb502a629aa5c3ed0aba4372fd2ad795ea694042ba6105ba892b4\n",
    "\n",
    "Correct: 5 (0.25)\n",
    "\n",
    "Mixed: 4 (0.2)\n",
    "\n",
    "Incorrect: 8 (0.4)\n",
    "\n",
    "Successfull Failure: 3 (0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c8e2d-fca7-444c-a5b5-76d14efcb3a3",
   "metadata": {},
   "source": [
    "### V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c10d5bd-96fe-4687-8cf1-dfb36f9bb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_pipeline = SummaryPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ce0a20-cc94-47d1-9fec-3fe847b726ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f3fe8de73c4686a765172f5ea453b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summaries = sum_pipeline.call(load_format_pages([uber_text[page] for page in uber_text]))\n",
    "await save_summaries(summaries, path=\"v3_uber_generated_qa.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf9eedc-ef8a-4b09-b0f0-41ce663395a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81778506263401aa9cd10198ec75f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summaries = sum_pipeline.call(load_format_pages([lyft_text[page] for page in lyft_text]))\n",
    "await save_summaries(summaries, path=\"v3_lyft_generated_qa.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0e71e48-8bc2-4513-9dad-626fbe4acac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_data = []\n",
    "with jsonlines.Reader(open(\"v3_uber_generated_qa.jsonl\", \"rb\")) as reader:\n",
    "    for line in reader:\n",
    "        tune_data.append(line)\n",
    "with jsonlines.Reader(open(\"v3_lyft_generated_qa.jsonl\", \"rb\")) as reader:\n",
    "    for line in reader:\n",
    "        tune_data.append(line)\n",
    "tune_df = pd.DataFrame(tune_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a225101-a14d-44f7-a1c6-edea9961b832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the annual report of Uber Technologies...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "      <td>This is the annual report of Uber Technologies...</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The document appears to be a form for a compan...</td>\n",
       "      <td>_______________ Delaware45-2647441 (State or o...</td>\n",
       "      <td>The document appears to be a form for a compan...</td>\n",
       "      <td>_______________ Delaware45-2647441 (State or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The registrant is a well-known seasoned issuer...</td>\n",
       "      <td>k mark whether the registrant is a well-known ...</td>\n",
       "      <td>The registrant is a well-known seasoned issuer...</td>\n",
       "      <td>k mark whether the registrant is a well-known ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The registrant has submitted all required Inte...</td>\n",
       "      <td>whether the registrant has submitted electroni...</td>\n",
       "      <td>The registrant has submitted all required Inte...</td>\n",
       "      <td>whether the registrant has submitted electroni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The company is a large accelerated filer</td>\n",
       "      <td>Large accelerated filer\\n☒ Accelerated filer ☐...</td>\n",
       "      <td>The company is a large accelerated filer</td>\n",
       "      <td>Large accelerated filer\\n☒ Accelerated filer ☐...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  This is the annual report of Uber Technologies...   \n",
       "1  The document appears to be a form for a compan...   \n",
       "2  The registrant is a well-known seasoned issuer...   \n",
       "3  The registrant has submitted all required Inte...   \n",
       "4           The company is a large accelerated filer   \n",
       "\n",
       "                                             content  \\\n",
       "0  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...   \n",
       "1  _______________ Delaware45-2647441 (State or o...   \n",
       "2  k mark whether the registrant is a well-known ...   \n",
       "3  whether the registrant has submitted electroni...   \n",
       "4  Large accelerated filer\\n☒ Accelerated filer ☐...   \n",
       "\n",
       "                                               input  \\\n",
       "0  This is the annual report of Uber Technologies...   \n",
       "1  The document appears to be a form for a compan...   \n",
       "2  The registrant is a well-known seasoned issuer...   \n",
       "3  The registrant has submitted all required Inte...   \n",
       "4           The company is a large accelerated filer   \n",
       "\n",
       "                                              output  \n",
       "0  UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...  \n",
       "1  _______________ Delaware45-2647441 (State or o...  \n",
       "2  k mark whether the registrant is a well-known ...  \n",
       "3  whether the registrant has submitted electroni...  \n",
       "4  Large accelerated filer\\n☒ Accelerated filer ☐...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3683139c-4c19-432e-8749-1ce2a9ef4410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: c9dae5ed7286c881653e6421b85058a6074e58650828b0e80d55176e6cee8c65 . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='c9dae5ed7286c881653e6421b85058a6074e58650828b0e80d55176e6cee8c65')\n",
      "Tuning job submitted! Check status of job 13731 here: https://api.lamini.ai/train/13731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13731,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': 'c9dae5ed7286c881653e6421b85058a6074e58650828b0e80d55176e6cee8c65'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_llm = lamini.Lamini(model_name=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "base_llm.tune(tune_data, finetune_args={\"max_steps\": 2000, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd97263-cf19-4257-b76a-cc290d3f6134",
   "metadata": {},
   "source": [
    "meta-llama/Meta-Llama-3.1-8B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779506b-876c-4e74-bdbe-7894470847a6",
   "metadata": {},
   "source": [
    "This is from a previous run with different finetune args, this was using 500 steps with a learning rate of 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6a8b52f-c779-489c-ac40-de9f256bbd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae742ed142de4ec9ae27a9323ebc94e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"93d151c534c78c9ab1e7a6be0ac9abe445a5aec4b179aa0aad1a9e38631cec34\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13722.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c1568-b0e0-4d64-89f9-466c5c56eff8",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/1eOoOglkQRe_pRX6RoeZd72PoNIgCa0GhJuD5mnw29uo/edit?usp=sharing\n",
    "\n",
    "Correct: 0 (0)\n",
    "\n",
    "Mixed: 0 (0)\n",
    "\n",
    "Incorrect: 20 (1)\n",
    "\n",
    "Successfull Failure: 0 (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "683ca049-f6a3-4428-a90e-a1b490594fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23dddf9d795407190a64c313a8e1c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"3e0b53da66bad689d0107b6bb4e5f03ef0048113045cac3fcaf09f4dbe189e27\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13731.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b9386-2064-4aef-8559-2bb766202b64",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/11RneXqA3y8I7ZZh6X0bhdUseFbjW4kCf-p6jcJtCPZU/edit?usp=sharing\n",
    "\n",
    "Correct: 0 (0)\n",
    "\n",
    "Mixed: 0 (0)\n",
    "\n",
    "Incorrect: 20 (1)\n",
    "\n",
    "Successfull Failure: 0 (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e76eabb-5f02-4427-b628-20680d12d49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: 8901f7abc884d983bdfff67590a55b4f56015f9aba3aa3a7f79e0c0b7f7b599b . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='8901f7abc884d983bdfff67590a55b4f56015f9aba3aa3a7f79e0c0b7f7b599b')\n",
      "Tuning job submitted! Check status of job 13732 here: https://api.lamini.ai/train/13732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13732,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': '8901f7abc884d983bdfff67590a55b4f56015f9aba3aa3a7f79e0c0b7f7b599b'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_gemma = lamini.Lamini(model_name=\"google/gemma-2-9b-it\")\n",
    "base_gemma.tune(tune_data, finetune_args={\"max_steps\": 2000, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f505be66-7dec-4059-a688-a9ab9e040ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4c325416684006b1b618af2bff9a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: API error 524\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 150, in make_async_web_request\n",
      "    await handle_error(resp)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 252, in handle_error\n",
      "    raise APIError(f\"API error {description}\")\n",
      "lamini.error.error.APIError: API error 524\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n",
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: API error 524\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 150, in make_async_web_request\n",
      "    await handle_error(resp)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 252, in handle_error\n",
      "    raise APIError(f\"API error {description}\")\n",
      "lamini.error.error.APIError: API error 524\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n",
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: API error 524\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 150, in make_async_web_request\n",
      "    await handle_error(resp)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 252, in handle_error\n",
      "    raise APIError(f\"API error {description}\")\n",
      "lamini.error.error.APIError: API error 524\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n",
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: API error 524\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 150, in make_async_web_request\n",
      "    await handle_error(resp)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 252, in handle_error\n",
      "    raise APIError(f\"API error {description}\")\n",
      "lamini.error.error.APIError: API error 524\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/contract-poc-jPOtkveY-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n"
     ]
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"ed1a20134bbfeca4c4e9963dad3d56db0c81bed6168a633a8a693649f7ab26a1\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13723.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ea70d-e439-4b12-83b3-9d553973612b",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/1SZrI3xBcKF1B4MFrB5Jz1FwzTEkuh0glqruYoG7ruwE/edit?usp=sharing\n",
    "\n",
    "Correct: 10 (0.50)\n",
    "\n",
    "Mixed: 7 (0.35)\n",
    "\n",
    "Incorrect: 3 (0.15)\n",
    "\n",
    "Successfull Failure: 0 (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02f3a1b1-6b8b-40ee-832d-204d2af87c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263353bba9e84fa980558b19d77ab6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"0226291e7bba69c0bef0a9f28c8956a59a7212593bfa5807ead3115378ab3f48\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13732.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e186378-6b1f-4954-9883-d0277d8a282e",
   "metadata": {},
   "source": [
    "https://docs.google.com/spreadsheets/d/1--eFNnJtpRTkiBagyOSQnyxXvb6XyZ59z31xDHDAk-s/edit?usp=sharing\n",
    "\n",
    "Correct: 9 (0.45)\n",
    "\n",
    "Mixed: 5 (0.25)\n",
    "\n",
    "Incorrect: 6 (0.3)\n",
    "\n",
    "Successfull Failure: 0 (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9da3f9e3-095e-4f9d-80e1-e91676d3656e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: 5492cf45eb13468b0067ffa0e175a6fe0a81bf83485dbed68386c7dd5e6b364d . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='5492cf45eb13468b0067ffa0e175a6fe0a81bf83485dbed68386c7dd5e6b364d')\n",
      "Tuning job submitted! Check status of job 13733 here: https://api.lamini.ai/train/13733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13733,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': '5492cf45eb13468b0067ffa0e175a6fe0a81bf83485dbed68386c7dd5e6b364d'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_mistral = lamini.Lamini(model_name=\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
    "base_mistral.tune(tune_data, finetune_args={\"max_steps\": 2000, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d4e7d9e-2e9b-406a-8b63-8d77343206f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9602039508a44e4b4bd328099415554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"b19ff90ee72d63a4019210db7f717341ad2f43e64fb11fb46e6ce7f7e253ef6b\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "model_responses = await save_answers_to_csv(answers, path=\"responses/gold_test_responses_13733.csv\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03b206-565e-40f6-894d-34902152da2b",
   "metadata": {},
   "source": [
    "### V4\n",
    "\n",
    "Shifting to Mistral as it had good base performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0cbc2-fafb-432b-a72a-d97b5ea84805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
