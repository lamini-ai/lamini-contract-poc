{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c92ada4-1ad9-42d0-8b9c-d82bc4cb6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lamini\n",
    "import pandas as pd\n",
    "from lamini.index.lamini_index import LaminiIndex\n",
    "\n",
    "from contract_poc.utils import read_pdf, build_prompts_from_dataframe\n",
    "from contract_poc.qa_pipeline import QuestionAnswerPipeline, load_qa_prompts, save_answers\n",
    "from contract_poc.answer_pipeline import AnswerPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab6187b8-1522-4123-9e54-21d4ef261a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_text = read_pdf(\"data/uber_2021.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2b79946-de8e-4729-8c51-db1233d92577",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_text = read_pdf(\"data/lyft_2021.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae7af9f2-793c-42ac-993b-d617cf3c03b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uber_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db339681-18a3-4b70-9772-ce4433d464a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyft_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404e84b-d8f3-4862-b5f5-e0c4ca638e35",
   "metadata": {},
   "source": [
    "# Build Index for PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584ab365-c814-476c-b1f9-895fd32f8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_pages = []\n",
    "for page in uber_text:\n",
    "    index_pages.append([uber_text[page]])\n",
    "for page in lyft_text:\n",
    "    index_pages.append([lyft_text[page]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb290394-a909-486a-8367-7b734de83746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7592efbc-01f4-41ad-89d2-9f9d62ebe8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index with 545 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████▋     | 474/545 [13:25<36:36, 30.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in adding embeddings to index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████▏| 534/545 [32:30<58:29, 319.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in adding embeddings to index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 545/545 [32:46<00:00,  3.61s/it]\n"
     ]
    }
   ],
   "source": [
    "llm_index = LaminiIndex.build_index(index_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bf2bfae-719a-4c61-9bf0-588c9342ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_index.save_index(\"model_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f902e9a-c537-4d41-ba11-ffa464e1d9a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LaminiIndex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm_index \u001b[38;5;241m=\u001b[39m \u001b[43mLaminiIndex\u001b[49m\u001b[38;5;241m.\u001b[39mload_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LaminiIndex' is not defined"
     ]
    }
   ],
   "source": [
    "llm_index = LaminiIndex.load_index(\"model_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ac52f97-e65c-415f-aba0-2bb29568f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = llm_index.get_embeddings(\"Ask three separate questions around a fact, table, or number within this text:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8a65d25-79dd-4699-be90-159f8e802753",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = llm_index.index.search(embed, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4eae4738-9c6f-42b6-8d4f-d3cf7ca5f9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[308, 360]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "185855c9-0d1b-45ff-abaa-65f18f3030ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[llm_index.splits[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fbc73-36d9-4308-8c51-d2d0d08bfeec",
   "metadata": {},
   "source": [
    "# QA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a0f81f-ce38-48bf-bf69-2563b2987cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pipeline = QuestionAnswerPipeline(\n",
    "    question_system_prompt = \"Ask three separate questions around a fact, table, or number within this text: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b326dc4-bc28-45f0-ac7b-6d04b8ca612e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving answers: 0 answers [00:00, ? answers/s]\u001b[A\n",
      "Saving answers: 1 answers [00:24, 24.67s/ answers]\u001b[A\n",
      "Saving answers: 6 answers [00:25,  3.15s/ answers]\u001b[A\n",
      "Saving answers: 11 answers [00:25,  1.44s/ answers]\u001b[A\n",
      "Saving answers: 15 answers [00:38,  1.44s/ answers]\u001b[A\n",
      "Saving answers: 16 answers [01:13,  5.03s/ answers]\u001b[A\n",
      "Saving answers: 21 answers [01:16,  3.34s/ answers]\u001b[A\n",
      "Saving answers: 26 answers [01:25,  2.80s/ answers]\u001b[A\n",
      "Saving answers: 31 answers [01:33,  2.35s/ answers]\u001b[A\n",
      "Saving answers: 36 answers [02:02,  3.50s/ answers]\u001b[A\n",
      "Saving answers: 41 answers [02:03,  2.43s/ answers]\u001b[A\n",
      "Saving answers: 46 answers [02:23,  2.94s/ answers]\u001b[A\n",
      "Saving answers: 51 answers [02:24,  2.11s/ answers]\u001b[A\n",
      "Saving answers: 56 answers [02:25,  1.49s/ answers]\u001b[A\n",
      "Saving answers: 61 answers [02:52,  2.71s/ answers]\u001b[A\n",
      "Saving answers: 66 answers [02:53,  1.92s/ answers]\u001b[A\n",
      "Saving answers: 71 answers [03:14,  2.62s/ answers]\u001b[A\n",
      "Saving answers: 76 answers [03:15,  1.89s/ answers]\u001b[A\n",
      "Saving answers: 81 answers [03:47,  3.27s/ answers]\u001b[A\n",
      "Saving answers: 86 answers [04:03,  3.21s/ answers]\u001b[A\n",
      "Saving answers: 91 answers [04:04,  2.33s/ answers]\u001b[A\n",
      "Saving answers: 96 answers [04:16,  2.35s/ answers]\u001b[A\n",
      "Saving answers: 101 answers [04:41,  3.13s/ answers]\u001b[A\n",
      "Saving answers: 106 answers [05:02,  3.45s/ answers]\u001b[A\n",
      "Saving answers: 111 answers [05:06,  2.69s/ answers]\u001b[A\n",
      "Saving answers: 116 answers [05:07,  1.90s/ answers]\u001b[A\n",
      "Saving answers: 121 answers [05:18,  2.02s/ answers]\u001b[A\n",
      "Saving answers: 126 answers [05:25,  1.85s/ answers]\u001b[A\n",
      "Saving answers: 131 answers [06:14,  4.18s/ answers]\u001b[A\n",
      "Saving answers: 136 answers [06:16,  3.08s/ answers]\u001b[A\n",
      "Saving answers: 141 answers [06:20,  2.40s/ answers]\u001b[A\n",
      "Saving answers: 146 answers [06:21,  1.72s/ answers]\u001b[A\n",
      "Saving answers: 151 answers [06:28,  1.66s/ answers]\u001b[A\n",
      "Saving answers: 156 answers [06:29,  1.19s/ answers]\u001b[A\n",
      "Saving answers: 161 answers [06:36,  1.28s/ answers]\u001b[A\n",
      "Saving answers: 166 answers [06:50,  1.71s/ answers]\u001b[A\n",
      "Saving answers: 171 answers [07:02,  1.93s/ answers]\u001b[A\n",
      "Saving answers: 176 answers [07:22,  2.53s/ answers]\u001b[A\n",
      "Saving answers: 181 answers [07:27,  2.11s/ answers]\u001b[A\n",
      "Saving answers: 186 answers [07:32,  1.76s/ answers]\u001b[A\n",
      "Saving answers: 191 answers [07:33,  1.30s/ answers]\u001b[A\n",
      "Saving answers: 196 answers [08:01,  2.55s/ answers]\u001b[A\n",
      "Saving answers: 201 answers [08:08,  2.25s/ answers]\u001b[A\n",
      "Saving answers: 206 answers [08:10,  1.67s/ answers]\u001b[A\n",
      "Saving answers: 211 answers [08:22,  1.91s/ answers]\u001b[A\n",
      "Saving answers: 216 answers [08:45,  2.72s/ answers]\u001b[A\n",
      "Saving answers: 221 answers [08:47,  1.99s/ answers]\u001b[A\n",
      "Saving answers: 226 answers [08:51,  1.64s/ answers]\u001b[A\n",
      "Saving answers: 231 answers [08:55,  1.37s/ answers]\u001b[A\n",
      "Saving answers: 236 answers [09:31,  3.12s/ answers]\u001b[A\n",
      "Saving answers: 241 answers [09:33,  2.33s/ answers]\u001b[A\n",
      "Saving answers: 246 answers [09:35,  1.77s/ answers]\u001b[A\n",
      "Saving answers: 251 answers [09:37,  1.32s/ answers]\u001b[A\n",
      "Saving answers: 256 answers [10:26,  3.90s/ answers]\u001b[A\n",
      "Saving answers: 261 answers [10:36,  3.30s/ answers]\u001b[A\n",
      "Saving answers: 266 answers [10:40,  2.58s/ answers]\u001b[A\n",
      "Saving answers: 271 answers [10:47,  2.23s/ answers]\u001b[A\n",
      "Saving answers: 276 answers [10:49,  1.63s/ answers]\u001b[A\n",
      "Saving answers: 281 answers [10:53,  1.43s/ answers]\u001b[A\n",
      "Saving answers: 286 answers [11:01,  1.44s/ answers]\u001b[A\n",
      "Saving answers: 291 answers [11:08,  1.47s/ answers]\u001b[A\n",
      "Saving answers: 296 answers [11:14,  1.39s/ answers]\u001b[A\n",
      "Saving answers: 301 answers [11:50,  3.14s/ answers]\u001b[A\n",
      "Saving answers: 306 answers [11:56,  2.55s/ answers]\u001b[A\n",
      "Saving answers: 311 answers [11:59,  1.92s/ answers]\u001b[A\n",
      "Saving answers: 316 answers [12:09,  1.98s/ answers]\u001b[A\n",
      "Saving answers: 321 answers [12:11,  1.52s/ answers]\u001b[A\n",
      "Saving answers: 326 answers [12:39,  2.70s/ answers]\u001b[A\n",
      "Saving answers: 331 answers [12:45,  2.28s/ answers]\u001b[A\n",
      "Saving answers: 336 answers [12:54,  2.13s/ answers]\u001b[A\n",
      "Saving answers: 341 answers [12:55,  1.55s/ answers]\u001b[A\n",
      "Saving answers: 346 answers [12:56,  1.17s/ answers]\u001b[A\n",
      "Saving answers: 351 answers [13:08,  1.50s/ answers]\u001b[A\n",
      "Saving answers: 356 answers [13:43,  3.19s/ answers]\u001b[A\n",
      "Saving answers: 361 answers [13:44,  2.25s/ answers]\u001b[A\n",
      "Saving answers: 366 answers [13:45,  1.63s/ answers]\u001b[A\n",
      "Saving answers: 371 answers [13:47,  1.28s/ answers]\u001b[A\n",
      "Saving answers: 376 answers [14:32,  3.61s/ answers]\u001b[A\n",
      "Saving answers: 381 answers [14:37,  2.82s/ answers]\u001b[A\n",
      "Saving answers: 386 answers [14:42,  2.27s/ answers]\u001b[A\n",
      "Saving answers: 391 answers [14:54,  2.33s/ answers]\u001b[A\n",
      "Saving answers: 396 answers [14:59,  1.92s/ answers]\u001b[A\n",
      "Saving answers: 401 answers [15:07,  1.82s/ answers]\u001b[A\n",
      "Saving answers: 406 answers [15:11,  1.51s/ answers]\u001b[A\n",
      "Saving answers: 411 answers [15:28,  2.07s/ answers]\u001b[A\n",
      "Saving answers: 416 answers [15:41,  2.24s/ answers]\u001b[A\n",
      "Saving answers: 421 answers [15:55,  2.40s/ answers]\u001b[A\n",
      "Saving answers: 426 answers [15:55,  1.72s/ answers]\u001b[A\n",
      "Saving answers: 431 answers [16:08,  1.94s/ answers]\u001b[A\n",
      "Saving answers: 436 answers [16:10,  1.49s/ answers]\u001b[A\n",
      "Saving answers: 441 answers [16:45,  3.12s/ answers]\u001b[A\n",
      "Saving answers: 446 answers [16:52,  2.64s/ answers]\u001b[A\n",
      "Saving answers: 451 answers [16:53,  1.91s/ answers]\u001b[A\n",
      "Saving answers: 456 answers [17:01,  1.80s/ answers]\u001b[A\n",
      "Saving answers: 461 answers [17:37,  3.42s/ answers]\u001b[A\n",
      "Saving answers: 466 answers [17:38,  2.47s/ answers]\u001b[A\n",
      "Saving answers: 471 answers [17:43,  2.02s/ answers]\u001b[A\n",
      "Saving answers: 476 answers [17:50,  1.85s/ answers]\u001b[A\n",
      "Saving answers: 481 answers [18:03,  2.08s/ answers]\u001b[A\n",
      "Saving answers: 491 answers [18:04,  1.16s/ answers]\u001b[A\n",
      "Saving answers: 496 answers [18:36,  2.45s/ answers]\u001b[A\n",
      "Saving answers: 501 answers [18:42,  2.12s/ answers]\u001b[A\n",
      "Saving answers: 506 answers [18:43,  1.59s/ answers]\u001b[A\n",
      "Saving answers: 511 answers [18:48,  1.46s/ answers]\u001b[A\n",
      "Saving answers: 516 answers [19:29,  3.36s/ answers]\u001b[A\n",
      "Saving answers: 521 answers [19:30,  2.43s/ answers]\u001b[A\n",
      "Saving answers: 526 answers [19:47,  2.72s/ answers]\u001b[A\n",
      "Saving answers: 531 answers [19:51,  2.14s/ answers]\u001b[A\n",
      "Saving answers: 536 answers [19:58,  1.97s/ answers]\u001b[A\n",
      "Saving answers: 541 answers [20:07,  1.92s/ answers]\u001b[A\n",
      "Saving answers: 546 answers [20:12,  1.59s/ answers]\u001b[A\n",
      "Saving answers: 551 answers [20:36,  2.60s/ answers]\u001b[A\n",
      "Saving answers: 556 answers [21:02,  3.37s/ answers]\u001b[A\n",
      "Saving answers: 561 answers [21:03,  2.41s/ answers]\u001b[A\n",
      "Saving answers: 566 answers [21:15,  2.38s/ answers]\u001b[A\n",
      "Saving answers: 571 answers [21:23,  2.17s/ answers]\u001b[A\n",
      "Saving answers: 576 answers [21:31,  1.97s/ answers]\u001b[A\n",
      "Saving answers: 581 answers [21:31,  1.43s/ answers]\u001b[A\n",
      "Saving answers: 586 answers [21:52,  2.23s/ answers]\u001b[A\n",
      "Saving answers: 591 answers [21:53,  1.61s/ answers]\u001b[A\n",
      "Saving answers: 596 answers [22:00,  1.57s/ answers]\u001b[A\n",
      "Saving answers: 601 answers [22:04,  1.35s/ answers]\u001b[A\n",
      "Saving answers: 606 answers [22:21,  1.94s/ answers]\u001b[A\n",
      "Saving answers: 611 answers [22:21,  1.37s/ answers]\u001b[A\n",
      "Saving answers: 616 answers [22:34,  1.70s/ answers]\u001b[A\n",
      "Saving answers: 621 answers [23:04,  3.04s/ answers]\u001b[A\n",
      "Saving answers: 626 answers [23:11,  2.53s/ answers]\u001b[A\n",
      "Saving answers: 636 answers [23:11,  1.38s/ answers]\u001b[A\n",
      "Saving answers: 640 answers [23:28,  1.38s/ answers]\u001b[A\n",
      "Saving answers: 641 answers [23:46,  2.76s/ answers]\u001b[A\n",
      "Saving answers: 646 answers [23:54,  2.44s/ answers]\u001b[A\n",
      "Saving answers: 651 answers [23:59,  2.06s/ answers]\u001b[A\n",
      "Saving answers: 656 answers [24:01,  1.60s/ answers]\u001b[A\n",
      "Saving answers: 661 answers [24:12,  1.76s/ answers]\u001b[A\n",
      "Saving answers: 666 answers [24:33,  2.46s/ answers]\u001b[A\n",
      "Saving answers: 671 answers [24:35,  1.85s/ answers]\u001b[A\n",
      "Saving answers: 676 answers [24:43,  1.82s/ answers]\u001b[A\n",
      "Saving answers: 681 answers [24:57,  2.08s/ answers]\u001b[A\n",
      "Saving answers: 686 answers [25:33,  3.59s/ answers]\u001b[A\n",
      "Saving answers: 691 answers [25:33,  2.54s/ answers]\u001b[A\n",
      "Saving answers: 696 answers [25:34,  1.83s/ answers]\u001b[A\n",
      "Saving answers: 701 answers [25:54,  2.46s/ answers]\u001b[A\n",
      "Saving answers: 706 answers [26:23,  3.46s/ answers]\u001b[A\n",
      "Saving answers: 711 answers [26:23,  2.46s/ answers]\u001b[A\n",
      "Saving answers: 716 answers [26:23,  1.73s/ answers]\u001b[A\n",
      "Saving answers: 720 answers [26:38,  1.73s/ answers]\u001b[A\n",
      "Saving answers: 721 answers [26:50,  2.79s/ answers]\u001b[A\n",
      "Saving answers: 726 answers [27:01,  2.64s/ answers]\u001b[A\n",
      "Saving answers: 731 answers [27:05,  2.06s/ answers]\u001b[A\n",
      "Saving answers: 736 answers [27:05,  1.47s/ answers]\u001b[A\n",
      "Saving answers: 741 answers [27:13,  1.53s/ answers]\u001b[A\n",
      "Saving answers: 746 answers [27:45,  2.97s/ answers]\u001b[A\n",
      "Saving answers: 751 answers [27:56,  2.75s/ answers]\u001b[A\n",
      "Saving answers: 756 answers [28:03,  2.34s/ answers]\u001b[A\n",
      "Saving answers: 761 answers [28:09,  2.00s/ answers]\u001b[A\n",
      "Saving answers: 766 answers [28:16,  1.80s/ answers]\u001b[A\n",
      "Saving answers: 771 answers [28:46,  3.05s/ answers]\u001b[A\n",
      "Saving answers: 776 answers [28:48,  2.28s/ answers]\u001b[A\n",
      "Saving answers: 781 answers [29:06,  2.67s/ answers]\u001b[A\n",
      "Saving answers: 786 answers [29:08,  1.96s/ answers]\u001b[A\n",
      "Saving answers: 791 answers [29:14,  1.75s/ answers]\u001b[A\n",
      "Saving answers: 796 answers [29:15,  1.28s/ answers]\u001b[A\n",
      "Saving answers: 801 answers [29:36,  2.15s/ answers]\u001b[A\n",
      "Saving answers: 806 answers [29:56,  2.73s/ answers]\u001b[A\n",
      "Saving answers: 811 answers [29:58,  2.01s/ answers]\u001b[A\n",
      "Saving answers: 816 answers [30:10,  2.12s/ answers]\u001b[A\n",
      "Saving answers: 821 answers [30:17,  1.92s/ answers]\u001b[A\n",
      "Saving answers: 826 answers [30:25,  1.81s/ answers]\u001b[A\n",
      "Saving answers: 831 answers [31:01,  3.46s/ answers]\u001b[A\n",
      "Saving answers: 836 answers [31:07,  2.76s/ answers]\u001b[A\n",
      "Saving answers: 841 answers [31:08,  2.00s/ answers]\u001b[A\n",
      "Saving answers: 846 answers [31:08,  1.41s/ answers]\u001b[A\n",
      "Saving answers: 851 answers [31:20,  1.70s/ answers]\u001b[A\n",
      "Saving answers: 856 answers [31:22,  1.29s/ answers]\u001b[A"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m answers \u001b[38;5;241m=\u001b[39m qa_pipeline\u001b[38;5;241m.\u001b[39mcall(load_qa_prompts([uber_text[page] \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m uber_text]))\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m save_answers(answers, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muber_generated_qa.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m, print_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/git/lamini-gtm/PoCs/FactualQA/apple_legal_contracts/apple_legal_contracts/qa_pipeline.py:98\u001b[0m, in \u001b[0;36msave_answers\u001b[0;34m(answers, path, print_outputs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jsonlines\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m     97\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m tqdm(desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving answers\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m answers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m answers:\n\u001b[1;32m     99\u001b[0m         answer \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer\u001b[38;5;241m.\u001b[39mprompt,\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    102\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    103\u001b[0m         }\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m print_outputs:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/generation_pipeline.py:123\u001b[0m, in \u001b[0;36mGenerationPipeline.call\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    121\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m anext(iterator)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopAsyncIteration\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/generation_node.py:113\u001b[0m, in \u001b[0;36mGenerationNode.process_results\u001b[0;34m(self, prompt_async_iter)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_results\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt_async_iter: AsyncIterator[PromptObject]):\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Processes results returned from self.generate()\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    results: AsyncIterator returned from self.generate().\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m prompt_async_iter:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m a \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(a\u001b[38;5;241m.\u001b[39merror) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;66;03m# Result from the generation call to remote LLM inference API\u001b[39;00m\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;66;03m# failed, record the prompt.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py:69\u001b[0m, in \u001b[0;36mGenerationQueue.submit\u001b[0;34m(self, request, token_optimizer)\u001b[0m\n\u001b[1;32m     66\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m return_args_and_exceptions(process_generation_batch)\n\u001b[1;32m     67\u001b[0m async_iterator \u001b[38;5;241m=\u001b[39m map_unordered(wrapped, batches, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_max_workers())\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m async_iterator:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m     71\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py:137\u001b[0m, in \u001b[0;36mmap_unordered\u001b[0;34m(func, iterable, limit)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     aws \u001b[38;5;241m=\u001b[39m (func(x) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m iterable)\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m limit_concurrency(aws, limit):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py:166\u001b[0m, in \u001b[0;36mlimit_concurrency\u001b[0;34m(aws, limit)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pending:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m done, pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mwait(pending, return_when\u001b[38;5;241m=\u001b[39masyncio\u001b[38;5;241m.\u001b[39mFIRST_COMPLETED)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m done:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m done\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:464\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing coroutines is forbidden, use tasks explicitly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    463\u001b[0m loop \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mget_running_loop()\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m _wait(fs, timeout, return_when, loop)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:550\u001b[0m, in \u001b[0;36m_wait\u001b[0;34m(fs, timeout, return_when, loop)\u001b[0m\n\u001b[1;32m    547\u001b[0m     f\u001b[38;5;241m.\u001b[39madd_done_callback(_on_completion)\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m waiter\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout_handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: Request Timeout: The server did not respond in time.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 1058, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/streams.py\", line 643, in read\n",
      "    await self._waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 140, in make_async_web_request\n",
      "    async with client.post(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/client.py\", line 1359, in __aenter__\n",
      "    self._resp: _RetType = await self._coro\n",
      "                           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/client.py\", line 690, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 1053, in start\n",
      "    with self._timer:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/helpers.py\", line 749, in __exit__\n",
      "    raise asyncio.TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 159, in make_async_web_request\n",
      "    raise APIError(\n",
      "lamini.error.error.APIError: Request Timeout: The server did not respond in time.\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n",
      "Error in process_generation_batch, type: <class 'lamini.error.error.APIError'>, message: Request Timeout: The server did not respond in time.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 1058, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/streams.py\", line 643, in read\n",
      "    await self._waiter\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 140, in make_async_web_request\n",
      "    async with client.post(\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/client.py\", line 1359, in __aenter__\n",
      "    self._resp: _RetType = await self._coro\n",
      "                           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/client.py\", line 690, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/client_reqrep.py\", line 1053, in start\n",
      "    with self._timer:\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/aiohttp/helpers.py\", line 749, in __exit__\n",
      "    raise asyncio.TimeoutError from exc_val\n",
      "TimeoutError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 42, in process_generation_batch\n",
      "    result = await query_api(client, key, url, json, batch[\"type\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 85, in query_api\n",
      "    result = await pipeline_client.completions(client, key, url, json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/api/pipeline_client.py\", line 17, in completions\n",
      "    result = await make_async_web_request(client, key, url, \"post\", json)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/api/rest_requests.py\", line 159, in make_async_web_request\n",
      "    raise APIError(\n",
      "lamini.error.error.APIError: Request Timeout: The server did not respond in time.\n",
      "Stack (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/generation_queue_3_10.py\", line 177, in _return_args_and_exceptions\n",
      "    return *args, await func(*args)\n",
      "  File \"/Users/powerml/Library/Caches/pypoetry/virtualenvs/apple-legal-contracts-vyiYZUr_-py3.12/lib/python3.12/site-packages/lamini/generation/process_generation_batch.py\", line 44, in process_generation_batch\n",
      "    logger.error(\n"
     ]
    }
   ],
   "source": [
    "answers = qa_pipeline.call(load_qa_prompts([uber_text[page] for page in uber_text]))\n",
    "await save_answers(answers, path=\"uber_generated_qa.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e368e2-5c9e-4d64-9b13-818bdabd46f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e8e895722644b6aabc913b80dd94e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers = qa_pipeline.call(load_qa_prompts([lyft_text[page] for page in lyft_text]))\n",
    "await save_answers(answers, path=\"lyft_generated_qa.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da137be0-09f5-495e-8e4a-e2c2e04770de",
   "metadata": {},
   "source": [
    "# Overfitting to eval set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f927929-2d8e-4849-b109-4f5403370270",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_llm_one = lamini.Lamini(model_name = \"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "base_llm_two = lamini.Lamini(model_name = \"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d59cd7c7-7d98-4efa-951e-5e36d7cb2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv(\"tune_sets/Apple PoC - Uber_Lyft Eval Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b6ed2ac-4bdc-4b70-a066-7a2c31a17c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Direct Text with Answer</th>\n",
       "      <th>Text Source</th>\n",
       "      <th>Page Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What comprises the Lyft transportation network?</td>\n",
       "      <td>Our transportation network is comprised of:\\n•...</td>\n",
       "      <td>Lyft - 7</td>\n",
       "      <td>Our transportation network is comprised of:•\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Lyft's growth strategy?</td>\n",
       "      <td>Our Growth Strategy\\nTransportation represents...</td>\n",
       "      <td>Lyft - 9</td>\n",
       "      <td>We have invested in a patent program to identi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who is Lyft's main ridesharing competitors?</td>\n",
       "      <td>Our main ridesharing competitors in the United...</td>\n",
       "      <td>Lyft - 10</td>\n",
       "      <td>entrants in the market that may be well-establ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who is Lyft's main competitors in consumer veh...</td>\n",
       "      <td>Enterprise, Hertz and Avis Budget Group as wel...</td>\n",
       "      <td>Lyft - 10</td>\n",
       "      <td>entrants in the market that may be well-establ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the latest information on the workforc...</td>\n",
       "      <td>As of December 31, 2021, we had 4,453 employee...</td>\n",
       "      <td>Lyft - 12</td>\n",
       "      <td>adversely affect our business”, “Risk Factors—...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0    What comprises the Lyft transportation network?   \n",
       "1                    What is Lyft's growth strategy?   \n",
       "2        Who is Lyft's main ridesharing competitors?   \n",
       "3  Who is Lyft's main competitors in consumer veh...   \n",
       "4  What is the latest information on the workforc...   \n",
       "\n",
       "                             Direct Text with Answer Text Source  \\\n",
       "0  Our transportation network is comprised of:\\n•...    Lyft - 7   \n",
       "1  Our Growth Strategy\\nTransportation represents...    Lyft - 9   \n",
       "2  Our main ridesharing competitors in the United...   Lyft - 10   \n",
       "3  Enterprise, Hertz and Avis Budget Group as wel...   Lyft - 10   \n",
       "4  As of December 31, 2021, we had 4,453 employee...   Lyft - 12   \n",
       "\n",
       "                                        Page Content  \n",
       "0  Our transportation network is comprised of:•\\n...  \n",
       "1  We have invested in a patent program to identi...  \n",
       "2  entrants in the market that may be well-establ...  \n",
       "3  entrants in the market that may be well-establ...  \n",
       "4  adversely affect our business”, “Risk Factors—...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08082479-a6a2-49f8-ba39-c415e7c05e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2793b9d-7920-4a83-baa0-b0592c0a0e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = [\n",
    "    {\n",
    "        \"input\": row[\"Question\"],\n",
    "        \"output\": row[\"Direct Text with Answer\"]\n",
    "    }\n",
    "    for idx, row in eval_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd81c41-c931-4f9b-b5d1-16f1dc9d11c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What comprises the Lyft transportation network?',\n",
       " 'output': 'Our transportation network is comprised of:\\n• Ridesharing Marketplace. Our core offering since 2012 connects drivers with riders who need to get somewhere. The scale of our network enables us to predict demand and proactively incentivize drivers to be available for rides in the right place at the right time. This allows us to optimize earning opportunities for drivers and offer convenient rides for riders, creating sustainable value to both sides of our marketplace. Our ridesharing marketplace connects drivers with riders in cities across the United States and in select cities in Canada.\\n• Express Drive. Our flexible car rentals program for drivers who want to drive using our platform but do not have access to a vehicle that meets our requirements. Through our Express Drive program, drivers can enter into short-term rental agreements for vehicles that may be used to provide ridesharing services on the Lyft Platform.\\n• Lyft Rentals. In 2019, we launched Lyft Rentals to offer an attractive option for users who have long-distance trips, such as a weekend away. This is a separate consumer offering from Express Drive.\\n• Light Vehicles. We have a network of shared bikes and scooters (“Light Vehicles”) in a number of cities to address the needs of users who are looking for options that are more active, usually lower-priced, and often more efficient for short trips during heavy traffic. These modes can also help supplement the first-mile and last-mile of a multimodal trip with public transit.\\n• Public Transit. Available in select cities, our Transit offering integrates third-party public transit data into the Lyft App to offer users a robust view of transportation options around them and allows them to see transit routes to their destinations at no cost. Providing real-time public transit information is another step toward providing effective, equitable and sustainable transportation to our communities, and creating a more seamless and connected transportation network.\\n• Lyft Autonomous. We have a number of strategic partnerships that offer access to autonomous vehicles. Our Open Platform partnership with Motional (formerly Aptiv) has enabled the commercial deployment of a fleet of autonomous vehicles on our platform in Las Vegas. In July 2021, we completed a multi-element transaction with Woven Planet, a subsidiary of Toyota Motor Corporation, for the divestiture of certain assets related to our self-driving vehicle division, Level 5, as well as commercial agreements for the utilization of Lyft rideshare and fleet data to accelerate the safety and commercialization of the automated-driving vehicles that Woven Planet is developing. In December 2021, we launched an autonomous rideshare service in Miami with Ford and Argo AI, delivering on a shared commitment to deploy Ford’s autonomous vehicles, powered by the Argo Self-Driving System, on our ridesharing network.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d29ff-b7b8-4c5a-acb7-96239c333999",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_llm = lamini.Lamini(model_name = \"meta-llama/Llama-3.1-8B-Instruct\")\n",
    "base_llm.tune(eval_set, finetune_args={\"max_steps\":100, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c660f912-f51f-41b3-89d5-d69d980b9436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: d045bf11384d38141b0de24127c28e004e786112381c0c35d6d8132bcf40a381 . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='d045bf11384d38141b0de24127c28e004e786112381c0c35d6d8132bcf40a381')\n",
      "Tuning job submitted! Check status of job 13261 here: https://api.lamini.ai/train/13261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13261,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': 'd045bf11384d38141b0de24127c28e004e786112381c0c35d6d8132bcf40a381'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_llm_two.tune(eval_set, finetune_args={\"max_steps\":100, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313faba-66fe-4f20-a540-bfbfbc7895b8",
   "metadata": {},
   "source": [
    "Above model only got 16 out of 20 correct responses, trying a longer job. 250 was chosen as it has seen some success from other Factual QA fine tuning jobs. 500 is the next iteration if this one doesn't overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5b64ef3-2df5-435e-ab88-de629b99879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: ba03d48ea14451864d9ed30316c049192e394a3b4fd153d612953860fd44d1dd . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='ba03d48ea14451864d9ed30316c049192e394a3b4fd153d612953860fd44d1dd')\n",
      "Tuning job submitted! Check status of job 13264 here: https://api.lamini.ai/train/13264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13264,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': 'ba03d48ea14451864d9ed30316c049192e394a3b4fd153d612953860fd44d1dd'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_llm_two.tune(eval_set, finetune_args={\"max_steps\":250, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0f02130-0241-4e00-8c09-9d72a28294a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pairs uploaded to local.\n",
      "\n",
      "Your dataset id is: 0104c14b59bbb6204be8a8b519c72bd32a0d9455741aff015e7895cc247ff3b5 . Consider using this in the future to train using the same data. \n",
      "Eg: llm.train(data_or_dataset_id='0104c14b59bbb6204be8a8b519c72bd32a0d9455741aff015e7895cc247ff3b5')\n",
      "Tuning job submitted! Check status of job 13265 here: https://api.lamini.ai/train/13265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_id': 13265,\n",
       " 'status': 'CREATED',\n",
       " 'dataset_id': '0104c14b59bbb6204be8a8b519c72bd32a0d9455741aff015e7895cc247ff3b5'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_llm_two.tune(eval_set, finetune_args={\"max_steps\":500, \"learning_rate\":0.0001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb675ec3-952a-4fb4-873c-7c649229c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lamini.generation.generation_node import GenerationNode\n",
    "from lamini.generation.base_prompt_object import PromptObject\n",
    "from lamini.generation.generation_pipeline import GenerationPipeline\n",
    "\n",
    "class GenPipeline(GenerationPipeline):\n",
    "    def __init__(self, model_name):\n",
    "        super(GenPipeline, self).__init__()\n",
    "\n",
    "        self.generation_node = GenerationNode(model_name=model_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.generation_node(x, output_type={\"answer\":\"str\"})\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a9e0279-e668-44a3-b6cc-4de922b9cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_prompt_generator(\n",
    "    df: pd.DataFrame, \n",
    "    input_col: str = \"Question\", \n",
    "    output_col: str = \"Direct Text with Answer\",\n",
    "    content_col: str = \"Page Content\",\n",
    "    company_col: str = \"Text Source\"\n",
    "):\n",
    "    for idx, row in df.iterrows():\n",
    "        yield PromptObject(\n",
    "            prompt = row[input_col],\n",
    "            data = {\n",
    "                \"question\": row[input_col],\n",
    "                \"expected_output\": row[output_col],\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "717c585e-d2a4-46c4-ad80-278aa87b164e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664d9a4438074502a0b68fe38eb929f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"0abba8b3b71782bf9bbd48101e7def385e9663f9c76bd293f94184c8e8840ac0\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "await save_answers(answers, path=\"overfit_response.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1ceb00d-4ed0-4681-9d95-04954f918f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6e4491924c4418a39b8b93ca78f05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"42c5c00ff85f93b27ef2e88b4f0a13c0c54a60360ff176230b05a869cadda30c\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "await save_answers(answers, path=\"overfit_v2_response.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee47b93b-2078-471e-929c-35df8c2bda7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fa5707580540f6b9bb5ecb5372a9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"d9341ae5cfc60d5ed9e173954387404b6419ee201aa2baacb79fe4a6cef532a1\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "await save_answers(answers, path=\"overfit_v3_response.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cce70c-2b7a-40d8-9029-73ce758e653c",
   "metadata": {},
   "source": [
    "# Base Llama 3.2 responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61208840-1a18-47a1-a9b5-e613cd37db7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53ad91b06ab4d0db5ae6ca89431d7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generation_pipeline = GenPipeline(model_name = \"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "answers = generation_pipeline.call(simple_prompt_generator(eval_df))\n",
    "await save_answers(answers, path=\"base_llama_3_2_response.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb4a61b-e040-4f55-82a1-ab45aab87561",
   "metadata": {},
   "source": [
    "# Direct RAG (No index search, direct page as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d746bbe7-d7db-4252-9eb0-3018d6c51da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(row):\n",
    "    global uber_text\n",
    "    global lyft_text\n",
    "\n",
    "    company = row[\"Text Source\"].split(\" - \")[0].strip()\n",
    "    if company == \"Uber\":\n",
    "        text = uber_text\n",
    "    elif company == \"Lyft\":\n",
    "        text = lyft_text\n",
    "    else:\n",
    "        raise ValueError(f\"Company could not be found {company} on row {idx}\")\n",
    "\n",
    "    page_num = row[\"Text Source\"].split(\" - \")[1].strip()\n",
    "    page_index = f\"Page {page_num}\"\n",
    "    \n",
    "    if page_index in text:\n",
    "        return text[page_index]\n",
    "    else:\n",
    "        raise ValueError(f\"{page_index} was not found within {company} text\")\n",
    "\n",
    "eval_df[\"Page Content\"] = eval_df.apply(lambda row: get_page(row), axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "345ff313-2b76-4f5d-92c3-2b84fbbfee27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Our transportation network is comprised of:•\\n...\n",
       "1     We have invested in a patent program to identi...\n",
       "2     entrants in the market that may be well-establ...\n",
       "3     entrants in the market that may be well-establ...\n",
       "4     adversely affect our business”, “Risk Factors—...\n",
       "5     Because we stand at a pivotal moment in the fi...\n",
       "6     Risks Related to Operational FactorsOur limite...\n",
       "7     Moreover, we could be required or otherwise fi...\n",
       "8     Moreover, we could be required or otherwise fi...\n",
       "9     Cash FlowsThe following table summar\\nizes our...\n",
       "10    PART IITEM 1. BUSINESS\\nOverview\\nUber\\n Techn...\n",
       "11    Financial and Operational HighlightsYear Ended...\n",
       "12    •Interest income, which consists primarily of ...\n",
       "13    Gross Bookings. We  define Gross Bookings as t...\n",
       "14     The following table presents a reconciliation...\n",
       "15    the Premium and the assumed liabilities (inclu...\n",
       "16    Contract Balances and Remaining Performance Ob...\n",
       "17    Note 6 - Leases    Our\\n leases primarily incl...\n",
       "18    Note 8 – Long-Term Debt and Revolving Credit A...\n",
       "19    In the event we experience an ownership change...\n",
       "Name: Page Content, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df[\"Page Content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c14b31fa-d949-4d0b-a973-76d32dfbfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_pipeline = AnswerPipeline(model_name = \"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58deea22-cebe-45f7-bc0b-244597aff2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f3608e66ef4695a0191da9133800fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving answers: 0 answers [00:00, ? answers/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answers = answer_pipeline.call(build_prompts_from_dataframe(eval_df))\n",
    "await save_answers(answers, path=\"direct_rag_response.jsonl\", print_outputs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af2397-c486-4004-bf63-ef2144cad957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
